# è®­ç»ƒå‰æ£€æŸ¥æ¸…å•

åœ¨è¿è¡Œ `grpo.py` å¼€å§‹è®­ç»ƒä¹‹å‰ï¼Œè¯·ç¡®ä¿å®Œæˆä»¥ä¸‹æ­¥éª¤ï¼š

## âœ… å¿…éœ€æ­¥éª¤

### 1. å‡†å¤‡è®­ç»ƒæ•°æ®é›†

è®­ç»ƒæ•°æ®é›†è¿˜ä¸å­˜åœ¨ï¼Œéœ€è¦å…ˆåˆ›å»ºï¼š

```bash
cd /Users/zhuxuzhou/Documents/VQA_Auto/decider

# æ–¹å¼ 1: ä½¿ç”¨è‡ªåŠ¨åŒ–è„šæœ¬
./create_test_dataset.sh

# æ–¹å¼ 2: æ‰‹åŠ¨è¿è¡Œ
python prepare_training_data.py test_input_data.json \
    --output-dir ./test_training_data \
    --train-split 0.7 \
    --val-split 0.2 \
    --test-split 0.1 \
    --save-format huggingface
```

**éªŒè¯**: æ£€æŸ¥ `./test_training_data/` ç›®å½•æ˜¯å¦å­˜åœ¨ï¼Œä¸”åŒ…å« `train/`, `validation/`, `test/` å­ç›®å½•ã€‚

### 2. éªŒè¯é…ç½®æ–‡ä»¶

æ£€æŸ¥ `test_config.yaml` ä¸­çš„å…³é”®é…ç½®ï¼š

- âœ… `dataset_name`: `"./test_training_data"` ï¼ˆåº”è¯¥æŒ‡å‘è®­ç»ƒæ•°æ®é›†ç›®å½•ï¼‰
- âœ… `model_name_or_path`: `"Qwen/Qwen2-VL-7B-Instruct"` ï¼ˆæ¨¡å‹è·¯å¾„ï¼‰
- âœ… `available_agents`: åŒ…å« agent åˆ—è¡¨
- âœ… `output_dir`: `"./test_output"` ï¼ˆè¾“å‡ºç›®å½•ï¼‰

### 3. æ£€æŸ¥ Python ç¯å¢ƒ

ç¡®ä¿å®‰è£…äº†å¿…è¦çš„ä¾èµ–ï¼š

```bash
# æ£€æŸ¥å…³é”®ä¾èµ–
python -c "import transformers; print(f'transformers: {transformers.__version__}')"
python -c "import torch; print(f'torch: {torch.__version__}')"
python -c "import trl; print('trl: OK')"
python -c "import datasets; print('datasets: OK')"
```

å¦‚æœç¼ºå°‘ä¾èµ–ï¼Œå®‰è£…ï¼š

```bash
pip install transformers torch accelerate datasets trl peft
```

### 4. éªŒè¯æ¨¡å‹è®¿é—®

ç¡®ä¿å¯ä»¥è®¿é—® Qwen2-VL æ¨¡å‹ï¼ˆå¯èƒ½éœ€è¦ HuggingFace tokenï¼‰ï¼š

```python
from transformers import AutoProcessor

# æµ‹è¯•è®¿é—®ï¼ˆä¸å®Œæ•´åŠ è½½ï¼‰
try:
    processor = AutoProcessor.from_pretrained("Qwen/Qwen2-VL-7B-Instruct")
    print("âœ“ å¯ä»¥è®¿é—® Qwen2-VL æ¨¡å‹")
except Exception as e:
    print(f"âœ— æ— æ³•è®¿é—®æ¨¡å‹: {e}")
    print("  å¯èƒ½éœ€è¦è®¾ç½® HuggingFace token:")
    print("  export HF_TOKEN=your_token")
    print("  æˆ–è¿è¡Œ: huggingface-cli login")
```

### 5. æ£€æŸ¥æ˜¾å­˜

Qwen2-VL-7B éœ€è¦çº¦ 14GB æ˜¾å­˜ï¼ˆä½¿ç”¨ BF16ï¼‰ã€‚æ£€æŸ¥å¯ç”¨æ˜¾å­˜ï¼š

```bash
# å¦‚æœä½¿ç”¨ NVIDIA GPU
nvidia-smi

# æˆ–ä½¿ç”¨ Python
python -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}'); print(f'GPU count: {torch.cuda.device_count()}'); [print(f'GPU {i}: {torch.cuda.get_device_properties(i).total_memory / 1e9:.1f} GB') for i in range(torch.cuda.device_count())]"
```

å¦‚æœæ˜¾å­˜ä¸è¶³ï¼Œè€ƒè™‘ï¼š
- ä½¿ç”¨æ›´å°çš„æ¨¡å‹ï¼š`Qwen/Qwen2-VL-2B-Instruct`
- å‡å° `per_device_train_batch_size`
- ä½¿ç”¨ LoRAï¼ˆPEFTï¼‰

## ğŸš€ å¿«é€Ÿæ£€æŸ¥è„šæœ¬

è¿è¡Œä»¥ä¸‹å‘½ä»¤è¿›è¡Œå¿«é€Ÿæ£€æŸ¥ï¼š

```bash
cd /Users/zhuxuzhou/Documents/VQA_Auto/decider

# è¿è¡Œå¿«é€Ÿæ£€æŸ¥
python quick_test.py
```

## ğŸ“‹ è®­ç»ƒå‰æ£€æŸ¥æ¸…å•

- [ ] è®­ç»ƒæ•°æ®é›†å·²åˆ›å»ºï¼ˆ`./test_training_data/` å­˜åœ¨ï¼‰
- [ ] é…ç½®æ–‡ä»¶å·²æ›´æ–°ï¼ˆ`test_config.yaml`ï¼‰
- [ ] Python ä¾èµ–å·²å®‰è£…ï¼ˆtransformers, torch, trl ç­‰ï¼‰
- [ ] å¯ä»¥è®¿é—® Qwen2-VL æ¨¡å‹
- [ ] GPU æ˜¾å­˜å……è¶³ï¼ˆè‡³å°‘ 14GB æ¨èï¼‰
- [ ] è¾“å‡ºç›®å½•å¯å†™ï¼ˆ`./test_output/`ï¼‰

## ğŸ¯ å¼€å§‹è®­ç»ƒ

å®Œæˆæ‰€æœ‰æ£€æŸ¥åï¼Œè¿è¡Œï¼š

```bash
cd /Users/zhuxuzhou/Documents/VQA_Auto/decider

# ä½¿ç”¨æµ‹è¯•é…ç½®
python grpo.py --config test_config.yaml

# å¦‚æœé‡åˆ°é—®é¢˜ï¼Œå¯ä»¥æ·»åŠ è°ƒè¯•ä¿¡æ¯
python grpo.py --config test_config.yaml --logging_level DEBUG
```

## âš ï¸ å¸¸è§é—®é¢˜

### Q: è®­ç»ƒæ•°æ®é›†ä¸å­˜åœ¨ï¼Ÿ

A: è¿è¡Œ `./create_test_dataset.sh` æˆ–æ‰‹åŠ¨è¿è¡Œ `prepare_training_data.py`

### Q: æ¨¡å‹ä¸‹è½½å¤±è´¥ï¼Ÿ

A: 
1. æ£€æŸ¥ç½‘ç»œè¿æ¥
2. è®¾ç½® HuggingFace token: `export HF_TOKEN=your_token`
3. æˆ–è¿è¡Œ: `huggingface-cli login`

### Q: æ˜¾å­˜ä¸è¶³ï¼ˆOOMï¼‰ï¼Ÿ

A: 
1. å‡å° `per_device_train_batch_size`ï¼ˆåœ¨ `test_config.yaml` ä¸­ï¼‰
2. å¢åŠ  `gradient_accumulation_steps`
3. å‡å° `num_generations`
4. ä½¿ç”¨æ›´å°çš„æ¨¡å‹ï¼ˆ2Bï¼‰

### Q: æ‰¾ä¸åˆ°æ¨¡å—ï¼Ÿ

A: å®‰è£…ç¼ºå¤±çš„ä¾èµ–ï¼š
```bash
pip install transformers torch accelerate datasets trl peft
```

## ğŸ“ ä¸‹ä¸€æ­¥

å®Œæˆæ£€æŸ¥åï¼Œå¯ä»¥ï¼š
1. è¿è¡Œå°è§„æ¨¡æµ‹è¯•è®­ç»ƒ
2. æ£€æŸ¥è®­ç»ƒæ—¥å¿—å’Œè¾“å‡º
3. æ ¹æ®ç»“æœè°ƒæ•´é…ç½®
4. å‡†å¤‡çœŸå®æ•°æ®è¿›è¡Œå®Œæ•´è®­ç»ƒ

