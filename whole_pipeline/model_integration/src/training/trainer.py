"""
è®­ç»ƒå™¨
é›†æˆdataå’Œmodelæ¨¡å—ï¼Œæä¾›å®Œæ•´çš„è®­ç»ƒåŠŸèƒ½
"""
import logging
import torch
import torch.nn as nn
from torch.optim import AdamW, Adam, SGD
from torch.optim.lr_scheduler import (
    StepLR, CosineAnnealingLR, ReduceLROnPlateau,
    LinearLR, ExponentialLR
)
from typing import Dict, List, Optional, Any, Union
from pathlib import Path
import time
from tqdm import tqdm

# å¯¼å…¥dataå’Œmodelæ¨¡å—ï¼ˆä½¿ç”¨ç»å¯¹å¯¼å…¥ï¼‰
from data.data_pipeline import DataPipeline
from models.model_loader import load_model
from models.model_utils import freeze_model, print_model_summary, get_model_info
from training.callbacks import (
    Callback, EarlyStoppingCallback, ModelCheckpointCallback,
    LearningRateSchedulerCallback, TensorBoardCallback,
    ProgressBarCallback, CSVLoggerCallback
)
from training.evaluator import Evaluator, VQAEvaluator

logger = logging.getLogger(__name__)


class Trainer:
    """è®­ç»ƒå™¨ç±»"""
    
    def __init__(
        self,
        model: nn.Module,
        train_dataloader: torch.utils.data.DataLoader,
        val_dataloader: Optional[torch.utils.data.DataLoader] = None,
        optimizer: Optional[torch.optim.Optimizer] = None,
        scheduler: Optional[Any] = None,
        device: Optional[str] = None,
        callbacks: Optional[List[Callback]] = None,
        evaluator: Optional[Evaluator] = None,
        **kwargs
    ):
        """
        åˆå§‹åŒ–è®­ç»ƒå™¨
        
        Args:
            model: è¦è®­ç»ƒçš„æ¨¡å‹
            train_dataloader: è®­ç»ƒæ•°æ®åŠ è½½å™¨
            val_dataloader: éªŒè¯æ•°æ®åŠ è½½å™¨ï¼ˆå¯é€‰ï¼‰
            optimizer: ä¼˜åŒ–å™¨ï¼ˆå¦‚æœä¸ºNoneï¼Œä¼šä½¿ç”¨é»˜è®¤AdamWï¼‰
            scheduler: å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼ˆå¯é€‰ï¼‰
            device: è®¾å¤‡
            callbacks: å›è°ƒå‡½æ•°åˆ—è¡¨
            evaluator: è¯„ä¼°å™¨ï¼ˆå¦‚æœä¸ºNoneï¼Œä¼šåˆ›å»ºé»˜è®¤çš„ï¼‰
            **kwargs: å…¶ä»–å‚æ•°
                - num_epochs: è®­ç»ƒè½®æ•°
                - gradient_accumulation_steps: æ¢¯åº¦ç´¯ç§¯æ­¥æ•°
                - max_grad_norm: æ¢¯åº¦è£å‰ª
                - fp16: æ˜¯å¦ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ
                - save_dir: ä¿å­˜ç›®å½•
        """
        self.model = model
        self.train_dataloader = train_dataloader
        self.val_dataloader = val_dataloader
        
        # è®¾å¤‡
        self.device = device or next(model.parameters()).device
        self.model = self.model.to(self.device)
        
        # ä¼˜åŒ–å™¨
        if optimizer is None:
            self.optimizer = AdamW(model.parameters(), lr=3e-5)
        else:
            self.optimizer = optimizer
        
        # å­¦ä¹ ç‡è°ƒåº¦å™¨
        self.scheduler = scheduler
        
        # å›è°ƒå‡½æ•°
        self.callbacks = callbacks or []
        
        # è¯„ä¼°å™¨
        self.evaluator = evaluator or Evaluator(model, device=self.device)
        
        # è®­ç»ƒå‚æ•°
        self.num_epochs = kwargs.get('num_epochs', 3)
        self.gradient_accumulation_steps = kwargs.get('gradient_accumulation_steps', 1)
        self.max_grad_norm = kwargs.get('max_grad_norm', None)
        self.fp16 = kwargs.get('fp16', False)
        self.save_dir = kwargs.get('save_dir', 'checkpoints')
        
        # è®­ç»ƒçŠ¶æ€
        self.current_epoch = 0
        self.global_step = 0
        self.should_stop = False
        self.history = []
        
        # æ··åˆç²¾åº¦è®­ç»ƒ
        if self.fp16:
            try:
                from torch.cuda.amp import autocast, GradScaler
                self.scaler = GradScaler()
                self.use_amp = True
                logger.info("å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒï¼ˆFP16ï¼‰")
            except ImportError:
                logger.warning("æ— æ³•å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒï¼Œéœ€è¦CUDAæ”¯æŒ")
                self.use_amp = False
        else:
            self.use_amp = False
        
        # åˆ›å»ºä¿å­˜ç›®å½•
        Path(self.save_dir).mkdir(parents=True, exist_ok=True)
        
        logger.info(f"è®­ç»ƒå™¨åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"è®¾å¤‡: {self.device}")
        logger.info(f"è®­ç»ƒæ ·æœ¬æ•°: {len(train_dataloader.dataset)}")
        if val_dataloader:
            logger.info(f"éªŒè¯æ ·æœ¬æ•°: {len(val_dataloader.dataset)}")
    
    def train(self):
        """å¼€å§‹è®­ç»ƒ"""
        logger.info("=" * 60)
        logger.info("å¼€å§‹è®­ç»ƒ")
        logger.info("=" * 60)
        
        # æ‰“å°æ¨¡å‹ä¿¡æ¯
        print_model_summary(self.model)
        
        # è°ƒç”¨è®­ç»ƒå¼€å§‹å›è°ƒ
        self._call_callbacks('on_train_begin')
        
        try:
            for epoch in range(self.num_epochs):
                self.current_epoch = epoch
                
                # è°ƒç”¨epochå¼€å§‹å›è°ƒ
                self._call_callbacks('on_epoch_begin', epoch=epoch)
                
                # è®­ç»ƒä¸€ä¸ªepoch
                train_logs = self._train_epoch()
                
                # éªŒè¯ï¼ˆå¦‚æœæœ‰éªŒè¯é›†ï¼‰
                val_logs = {}
                if self.val_dataloader:
                    val_logs = self._validate()
                
                # åˆå¹¶æ—¥å¿—
                epoch_logs = {**train_logs, **val_logs}
                epoch_logs['epoch'] = epoch
                
                # è®°å½•å†å²
                self.history.append(epoch_logs)
                
                # è°ƒç”¨epochç»“æŸå›è°ƒ
                self._call_callbacks('on_epoch_end', epoch=epoch, logs=epoch_logs)
                
                # æ£€æŸ¥æ˜¯å¦æ—©åœ
                if self.should_stop:
                    logger.info("è®­ç»ƒæå‰åœæ­¢")
                    break
        
        except KeyboardInterrupt:
            logger.info("è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
        
        finally:
            # è°ƒç”¨è®­ç»ƒç»“æŸå›è°ƒ
            self._call_callbacks('on_train_end')
            logger.info("è®­ç»ƒå®Œæˆ")
    
    def _train_epoch(self) -> Dict[str, float]:
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        
        total_loss = 0.0
        num_batches = 0
        
        # è¿›åº¦æ¡
        pbar = tqdm(self.train_dataloader, desc=f"Epoch {self.current_epoch}")
        
        for batch_idx, batch in enumerate(pbar):
            # è°ƒç”¨batchå¼€å§‹å›è°ƒ
            self._call_callbacks('on_batch_begin', batch=batch_idx)
            
            try:
                # å‡†å¤‡è¾“å…¥ï¼ˆåŒ…å«éªŒè¯å’Œä¿®å¤ï¼‰
                batch = self._prepare_batch(batch)
                
                # å‰å‘ä¼ æ’­
                loss = self._train_step(batch)
            except RuntimeError as e:
                error_str = str(e)
                if "CUDA" in error_str or "device-side assert" in error_str or "index" in error_str.lower():
                    logger.error(f"CUDAé”™è¯¯åœ¨batch {batch_idx}: {e}")
                    logger.error("Batchå†…å®¹:")
                    for key, value in batch.items():
                        if isinstance(value, torch.Tensor):
                            # ç§»åŠ¨åˆ°CPUå†æ£€æŸ¥ï¼Œé¿å…CUDAé”™è¯¯
                            try:
                                value_cpu = value.cpu()
                                logger.error(f"  {key}: shape={value.shape}, dtype={value.dtype}, device={value.device}")
                                if 'ids' in key.lower() or 'mask' in key.lower():
                                    logger.error(f"    min={value_cpu.min().item()}, max={value_cpu.max().item()}")
                                    if value.numel() < 100:
                                        logger.error(f"    values={value_cpu.tolist()}")
                            except Exception as inner_e:
                                logger.error(f"  {key}: æ— æ³•æ£€æŸ¥è¯¦æƒ… - {inner_e}")
                        else:
                            logger.error(f"  {key}: {type(value)}")
                    raise
                else:
                    raise
            
            # ç´¯ç§¯æŸå¤±
            total_loss += loss
            num_batches += 1
            
            # æ›´æ–°è¿›åº¦æ¡
            pbar.set_postfix({'loss': f'{loss:.4f}'})
            
            # è°ƒç”¨batchç»“æŸå›è°ƒ
            batch_logs = {'loss': loss}
            self._call_callbacks('on_batch_end', batch=batch_idx, logs=batch_logs)
            
            self.global_step += 1
        
        # è®¡ç®—å¹³å‡æŸå¤±
        avg_loss = total_loss / num_batches if num_batches > 0 else 0.0
        
        return {'train_loss': avg_loss}
    
    def _train_step(self, batch: Dict[str, Any]) -> float:
        """æ‰§è¡Œä¸€ä¸ªè®­ç»ƒæ­¥éª¤"""
        # æ¸…é›¶æ¢¯åº¦
        self.optimizer.zero_grad()
        
        # å‰å‘ä¼ æ’­
        if self.use_amp:
            with torch.cuda.amp.autocast():
                outputs = self.model(**batch)
                loss = outputs.loss if hasattr(outputs, 'loss') else outputs['loss']
                loss = loss / self.gradient_accumulation_steps
        else:
            outputs = self.model(**batch)
            loss = outputs.loss if hasattr(outputs, 'loss') else outputs['loss']
            loss = loss / self.gradient_accumulation_steps
        
        # åå‘ä¼ æ’­
        if self.use_amp:
            self.scaler.scale(loss).backward()
        else:
            loss.backward()
        
        # æ¢¯åº¦ç´¯ç§¯
        if (self.global_step + 1) % self.gradient_accumulation_steps == 0:
            # æ¢¯åº¦è£å‰ª
            if self.max_grad_norm is not None:
                if self.use_amp:
                    self.scaler.unscale_(self.optimizer)
                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.max_grad_norm)
                    self.scaler.step(self.optimizer)
                    self.scaler.update()
                else:
                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.max_grad_norm)
                    self.optimizer.step()
            else:
                if self.use_amp:
                    self.scaler.step(self.optimizer)
                    self.scaler.update()
                else:
                    self.optimizer.step()
        
        return loss.item() * self.gradient_accumulation_steps
    
    def _validate(self) -> Dict[str, float]:
        """éªŒè¯"""
        logger.info("å¼€å§‹éªŒè¯...")
        
        # è°ƒç”¨éªŒè¯å¼€å§‹å›è°ƒ
        self._call_callbacks('on_validation_begin')
        
        # è¯„ä¼°
        val_logs = self.evaluator.evaluate(self.val_dataloader)
        
        # æ·»åŠ val_å‰ç¼€
        val_logs = {f'val_{k}': v for k, v in val_logs.items()}
        
        # è°ƒç”¨éªŒè¯ç»“æŸå›è°ƒ
        self._call_callbacks('on_validation_end', logs=val_logs)
        
        return val_logs
    
    # def _prepare_batch(self, batch: Dict[str, Any]) -> Dict[str, Any]:
    #     """
    #     å‡†å¤‡batchï¼Œç§»åŠ¨åˆ°è®¾å¤‡å¹¶éªŒè¯tensor shapeså’Œå€¼
        
    #     æ³¨æ„ï¼šBLIPç­‰æ¨¡å‹å¯¹attention_maskçš„å½¢çŠ¶å’Œå€¼æœ‰ä¸¥æ ¼è¦æ±‚
    #     """
    #     prepared_batch = {}
        
    #     # é¦–å…ˆéªŒè¯å…³é”®å­—æ®µ
    #     if 'input_ids' in batch:
    #         input_ids = batch['input_ids']
    #         if not isinstance(input_ids, torch.Tensor):
    #             raise TypeError(f"input_idsåº”è¯¥æ˜¯torch.Tensorï¼Œå¾—åˆ°{type(input_ids)}")
            
    #         # éªŒè¯input_ids shape
    #         if input_ids.dim() != 2:
    #             raise ValueError(f"input_idsåº”è¯¥æ˜¯2D tensor [batch_size, seq_len]ï¼Œå¾—åˆ°shape {input_ids.shape}")
            
    #         batch_size, seq_len = input_ids.shape
            
    #         # éªŒè¯attention_maskï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    #         if 'attention_mask' in batch:
    #             attention_mask = batch['attention_mask']
    #             if not isinstance(attention_mask, torch.Tensor):
    #                 raise TypeError(f"attention_maskåº”è¯¥æ˜¯torch.Tensorï¼Œå¾—åˆ°{type(attention_mask)}")
                
    #             # éªŒè¯attention_mask shape
    #             if attention_mask.shape != input_ids.shape:
    #                 logger.warning(
    #                     f"attention_mask shape {attention_mask.shape} ä¸ input_ids shape {input_ids.shape} ä¸åŒ¹é…ï¼Œ"
    #                     f"å°è¯•ä¿®å¤..."
    #                 )
    #                 # å°è¯•ä¿®å¤ï¼šå¦‚æœç»´åº¦ä¸åŒ¹é…ï¼Œå°è¯•reshapeæˆ–é‡æ–°åˆ›å»º
    #                 if attention_mask.dim() == 1 and len(attention_mask) == seq_len:
    #                     # å¦‚æœæ˜¯1Dä¸”é•¿åº¦åŒ¹é…ï¼Œæ‰©å±•åˆ°batchç»´åº¦
    #                     attention_mask = attention_mask.unsqueeze(0).expand(batch_size, -1)
    #                 elif attention_mask.dim() == 2 and attention_mask.size(0) == batch_size:
    #                     # å¦‚æœbatchç»´åº¦åŒ¹é…ä½†seq_lenä¸åŒ¹é…ï¼Œé‡æ–°åˆ›å»º
    #                     if attention_mask.size(1) != seq_len:
    #                         # é‡æ–°åˆ›å»ºattention_maskï¼šépaddingä½ç½®ä¸º1
    #                         pad_id = getattr(self.model.config, 'pad_token_id', None) if hasattr(self.model, 'config') else None
    #                         if pad_id is None:
    #                             # å¦‚æœæ²¡æœ‰pad_token_idï¼Œå‡è®¾æ‰€æœ‰é0ä½ç½®éƒ½æ˜¯æœ‰æ•ˆtoken
    #                             attention_mask = (input_ids != 0).long()
    #                         else:
    #                             attention_mask = (input_ids != pad_id).long()
    #                 else:
    #                     # å®Œå…¨é‡æ–°åˆ›å»º
    #                     pad_id = getattr(self.model.config, 'pad_token_id', None) if hasattr(self.model, 'config') else None
    #                     if pad_id is None:
    #                         attention_mask = (input_ids != 0).long()
    #                     else:
    #                         attention_mask = (input_ids != pad_id).long()
                    
    #                 logger.info(f"ä¿®å¤åçš„attention_mask shape: {attention_mask.shape}")
                
    #             # éªŒè¯attention_maskå€¼ï¼ˆåº”è¯¥æ˜¯0æˆ–1ï¼‰
    #             unique_values = torch.unique(attention_mask)
    #             invalid_values = unique_values[(unique_values != 0) & (unique_values != 1)]
    #             if len(invalid_values) > 0:
    #                 logger.warning(
    #                     f"attention_maskåŒ…å«éæ³•å€¼: {invalid_values.tolist()}ï¼Œ"
    #                     f"å°†clampåˆ°[0, 1]èŒƒå›´"
    #                 )
    #                 attention_mask = torch.clamp(attention_mask, 0, 1).long()
                
    #             prepared_batch['attention_mask'] = attention_mask.to(self.device)
            
    #         # éªŒè¯labelsï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    #         if 'labels' in batch:
    #             labels = batch['labels']
    #             if isinstance(labels, torch.Tensor):
    #                 if labels.shape != input_ids.shape:
    #                     logger.warning(
    #                         f"labels shape {labels.shape} ä¸ input_ids shape {input_ids.shape} ä¸åŒ¹é…"
    #                     )
    #                     # å°è¯•ä¿®å¤ï¼šå¦‚æœç»´åº¦ä¸åŒ¹é…
    #                     if labels.dim() == 1 and len(labels) == seq_len:
    #                         labels = labels.unsqueeze(0).expand(batch_size, -1)
    #                     elif labels.dim() == 2 and labels.size(0) == batch_size and labels.size(1) != seq_len:
    #                         # å¦‚æœseq_lenä¸åŒ¹é…ï¼Œå¯èƒ½éœ€è¦paddingæˆ–truncation
    #                         logger.error(f"æ— æ³•ä¿®å¤labels shapeä¸åŒ¹é…: {labels.shape} vs {input_ids.shape}")
    #                         raise ValueError(f"labels shapeä¸åŒ¹é…: {labels.shape} vs {input_ids.shape}")
    #                 prepared_batch['labels'] = labels.to(self.device)
            
    #         prepared_batch['input_ids'] = input_ids.to(self.device)
        
    #     # å¤„ç†å…¶ä»–å­—æ®µ
    #     for key, value in batch.items():
    #         if key not in prepared_batch:  # é¿å…é‡å¤å¤„ç†
    #             if isinstance(value, torch.Tensor):
    #                 prepared_batch[key] = value.to(self.device)
    #             elif isinstance(value, (list, tuple)) and len(value) > 0 and isinstance(value[0], torch.Tensor):
    #                 # å¤„ç†tensoråˆ—è¡¨ï¼ˆå¦‚pixel_valuesçš„batchï¼‰
    #                 prepared_batch[key] = [v.to(self.device) for v in value]
    #             else:
    #                 prepared_batch[key] = value
        
    #     # æœ€ç»ˆéªŒè¯ï¼šç¡®ä¿æ‰€æœ‰tensoréƒ½åœ¨åŒä¸€è®¾å¤‡ä¸Š
    #     for key, value in prepared_batch.items():
    #         if isinstance(value, torch.Tensor) and value.device != self.device:
    #             logger.warning(f"{key}ä¸åœ¨æ­£ç¡®è®¾å¤‡ä¸Š: {value.device} vs {self.device}ï¼Œç§»åŠ¨åˆ°{self.device}")
    #             prepared_batch[key] = value.to(self.device)
        
    #     return prepared_batch

    def _prepare_batch(self, batch: Dict[str, Any]) -> Dict[str, Any]:
        """
        å‡†å¤‡batchï¼Œç§»åŠ¨åˆ°è®¾å¤‡å¹¶éªŒè¯tensor shapeså’Œå€¼
        
        ç‰¹åˆ«æ³¨æ„BLIPæ¨¡å‹çš„ç‰¹æ®Šè¦æ±‚
        """
        prepared_batch = {}
        
        # è·å–æ¨¡å‹è¯è¡¨å¤§å°
        vocab_size = None
        text_vocab_size = None
        if hasattr(self.model, 'config'):
            vocab_size = getattr(self.model.config, 'vocab_size', None)
            # BLIPæœ‰å•ç‹¬çš„text_config
            if hasattr(self.model.config, 'text_config'):
                text_vocab_size = getattr(self.model.config.text_config, 'vocab_size', None)
        
        # ä½¿ç”¨text_vocab_sizeï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        effective_vocab_size = text_vocab_size or vocab_size
        
        if 'input_ids' in batch:
            input_ids = batch['input_ids']
            if not isinstance(input_ids, torch.Tensor):
                raise TypeError(f"input_idsåº”è¯¥æ˜¯torch.Tensorï¼Œå¾—åˆ°{type(input_ids)}")
            
            if input_ids.dim() != 2:
                raise ValueError(f"input_idsåº”è¯¥æ˜¯2D tensor [batch_size, seq_len]ï¼Œå¾—åˆ°shape {input_ids.shape}")
            
            batch_size, seq_len = input_ids.shape
            
            # åœ¨CPUä¸ŠéªŒè¯
            input_ids_cpu = input_ids.cpu()
            max_id = input_ids_cpu.max().item()
            min_id = input_ids_cpu.min().item()
            
            logger.info(f"ğŸ“Š input_idsç»Ÿè®¡: min={min_id}, max={max_id}, vocab_size={effective_vocab_size}")
            
            # æ£€æŸ¥å¹¶ä¿®å¤
            if effective_vocab_size is not None:
                if max_id >= effective_vocab_size or min_id < 0:
                    logger.error(f"âŒ input_idsè¶…å‡ºèŒƒå›´: [{min_id}, {max_id}] vs [0, {effective_vocab_size-1}]")
                    
                    # ä¿®å¤ç­–ç•¥
                    pad_id = getattr(self.model.config, 'pad_token_id', 0)
                    unk_id = getattr(self.model.config, 'unk_token_id', pad_id)
                    
                    logger.warning(f"   ğŸ”§ Clampingåˆ°æœ‰æ•ˆèŒƒå›´...")
                    input_ids_cpu = torch.clamp(input_ids_cpu, 0, effective_vocab_size - 1)
                    input_ids = input_ids_cpu
                    
                    logger.info(f"   âœ… ä¿®å¤å: min={input_ids.min().item()}, max={input_ids.max().item()}")
            
            prepared_batch['input_ids'] = input_ids.to(self.device)
            
            # ===== å…³é”®ï¼šå¤„ç† decoder_input_ids (BLIPç‰¹æœ‰) =====
            if 'decoder_input_ids' in batch:
                decoder_input_ids = batch['decoder_input_ids']
                if isinstance(decoder_input_ids, torch.Tensor):
                    decoder_input_ids_cpu = decoder_input_ids.cpu()
                    max_dec_id = decoder_input_ids_cpu.max().item()
                    min_dec_id = decoder_input_ids_cpu.min().item()
                    
                    logger.info(f"ğŸ“Š decoder_input_idsç»Ÿè®¡: min={min_dec_id}, max={max_dec_id}")
                    
                    if effective_vocab_size is not None:
                        if max_dec_id >= effective_vocab_size or min_dec_id < 0:
                            logger.error(f"âŒ decoder_input_idsè¶…å‡ºèŒƒå›´!")
                            decoder_input_ids_cpu = torch.clamp(decoder_input_ids_cpu, 0, effective_vocab_size - 1)
                            decoder_input_ids = decoder_input_ids_cpu
                            logger.info(f"   âœ… decoderä¿®å¤å: min={decoder_input_ids.min().item()}, max={decoder_input_ids.max().item()}")
                    
                    prepared_batch['decoder_input_ids'] = decoder_input_ids.to(self.device)
            
            # å¤„ç† attention_mask
            if 'attention_mask' in batch:
                attention_mask = batch['attention_mask']
                if not isinstance(attention_mask, torch.Tensor):
                    raise TypeError(f"attention_maskåº”è¯¥æ˜¯torch.Tensorï¼Œå¾—åˆ°{type(attention_mask)}")
                
                if attention_mask.shape != input_ids.shape:
                    logger.warning(f"attention_mask shapeä¸åŒ¹é…ï¼Œé‡æ–°åˆ›å»º...")
                    pad_id = getattr(self.model.config, 'pad_token_id', 0)
                    attention_mask = (input_ids != pad_id).long()
                
                # éªŒè¯å€¼ï¼ˆåœ¨CPUä¸Šï¼‰
                attention_mask_cpu = attention_mask.cpu()
                unique_values = torch.unique(attention_mask_cpu)
                if not all(v in [0, 1] for v in unique_values.tolist()):
                    logger.warning(f"attention_maskåŒ…å«éæ³•å€¼ï¼Œä¿®å¤ä¸­...")
                    attention_mask = torch.clamp(attention_mask_cpu, 0, 1).long()
                
                prepared_batch['attention_mask'] = attention_mask.to(self.device)
            
            # ===== å…³é”®ï¼šå¤„ç† decoder_attention_mask =====
            if 'decoder_attention_mask' in batch:
                decoder_attention_mask = batch['decoder_attention_mask']
                if isinstance(decoder_attention_mask, torch.Tensor):
                    decoder_attention_mask_cpu = decoder_attention_mask.cpu()
                    unique_values = torch.unique(decoder_attention_mask_cpu)
                    if not all(v in [0, 1] for v in unique_values.tolist()):
                        logger.warning(f"decoder_attention_maskåŒ…å«éæ³•å€¼ï¼Œä¿®å¤ä¸­...")
                        decoder_attention_mask = torch.clamp(decoder_attention_mask_cpu, 0, 1).long()
                    prepared_batch['decoder_attention_mask'] = decoder_attention_mask.to(self.device)
            
            # å¤„ç† labels
            if 'labels' in batch:
                labels = batch['labels']
                if isinstance(labels, torch.Tensor):
                    if labels.shape != input_ids.shape:
                        logger.warning(f"labels shape {labels.shape} ä¸ input_ids shape {input_ids.shape} ä¸åŒ¹é…")
                        if labels.dim() == 1 and len(labels) == seq_len:
                            labels = labels.unsqueeze(0).expand(batch_size, -1)
                        elif labels.dim() == 2 and labels.size(0) == batch_size and labels.size(1) != seq_len:
                            # å¯¹äºBLIPï¼Œlabelså¯èƒ½æ˜¯answerçš„token idsï¼Œé•¿åº¦å¯èƒ½ä¸åŒ
                            logger.info(f"labelsé•¿åº¦ä¸input_idsä¸åŒï¼Œè¿™å¯¹BLIPæ˜¯æ­£å¸¸çš„")
                    
                    # éªŒè¯labelså€¼ï¼ˆåœ¨CPUä¸Šï¼‰
                    labels_cpu = labels.cpu()
                    valid_labels = labels_cpu[labels_cpu != -100]
                    if len(valid_labels) > 0:
                        max_label = valid_labels.max().item()
                        min_label = valid_labels.min().item()
                        
                        logger.info(f"ğŸ“Š labelsç»Ÿè®¡: min={min_label}, max={max_label} (å¿½ç•¥-100)")
                        
                        if effective_vocab_size is not None:
                            if max_label >= effective_vocab_size or min_label < 0:
                                logger.error(f"âŒ labelsè¶…å‡ºèŒƒå›´: [{min_label}, {max_label}] vs [0, {effective_vocab_size-1}]")
                                logger.warning(f"   ğŸ”§ å°†éæ³•labelsè®¾ç½®ä¸º-100...")
                                
                                # åˆ›å»ºmaskå¹¶æ›¿æ¢
                                mask = (labels_cpu != -100) & ((labels_cpu < 0) | (labels_cpu >= effective_vocab_size))
                                labels_cpu[mask] = -100
                                labels = labels_cpu
                                
                                logger.info(f"   âœ… labelsä¿®å¤å®Œæˆ")
                    
                    prepared_batch['labels'] = labels.to(self.device)
        
        # å¤„ç†å…¶ä»–å­—æ®µ
        for key, value in batch.items():
            if key not in prepared_batch:
                if isinstance(value, torch.Tensor):
                    prepared_batch[key] = value.to(self.device)
                elif isinstance(value, (list, tuple)) and len(value) > 0 and isinstance(value[0], torch.Tensor):
                    prepared_batch[key] = [v.to(self.device) for v in value]
                else:
                    prepared_batch[key] = value
        
        return prepared_batch
    
    def _call_callbacks(self, method_name: str, **kwargs):
        """è°ƒç”¨å›è°ƒå‡½æ•°"""
        for callback in self.callbacks:
            if hasattr(callback, method_name):
                try:
                    getattr(callback, method_name)(self, **kwargs)
                except Exception as e:
                    logger.error(f"å›è°ƒå‡½æ•° {callback.__class__.__name__}.{method_name} æ‰§è¡Œå¤±è´¥: {e}")
    
    def save_checkpoint(self, filepath: str, **kwargs):
        """ä¿å­˜æ£€æŸ¥ç‚¹"""
        checkpoint = {
            'epoch': self.current_epoch,
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'history': self.history,
            **kwargs
        }
        
        if self.scheduler:
            checkpoint['scheduler_state_dict'] = self.scheduler.state_dict()
        
        torch.save(checkpoint, filepath)
        logger.info(f"æ£€æŸ¥ç‚¹å·²ä¿å­˜: {filepath}")
    
    def load_checkpoint(self, filepath: str):
        """åŠ è½½æ£€æŸ¥ç‚¹"""
        checkpoint = torch.load(filepath, map_location=self.device)
        
        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        self.current_epoch = checkpoint.get('epoch', 0)
        self.history = checkpoint.get('history', [])
        
        if self.scheduler and 'scheduler_state_dict' in checkpoint:
            self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])
        
        logger.info(f"æ£€æŸ¥ç‚¹å·²åŠ è½½: {filepath}")


def create_trainer_from_config(
    data_config_path: str,
    model_name: str,
    model_type: Optional[str] = None,
    task: str = 'vqa',
    **kwargs
) -> Trainer:
    """
    ä»é…ç½®æ–‡ä»¶åˆ›å»ºè®­ç»ƒå™¨
    
    Args:
        data_config_path: æ•°æ®é…ç½®æ–‡ä»¶è·¯å¾„
        model_name: æ¨¡å‹åç§°
        model_type: æ¨¡å‹ç±»å‹
        task: ä»»åŠ¡ç±»å‹
        **kwargs: å…¶ä»–è®­ç»ƒå‚æ•°
        
    Returns:
        Trainerå®ä¾‹
    """
    # 1. åŠ è½½æ•°æ®
    logger.info("åŠ è½½æ•°æ®...")
    pipeline = DataPipeline(data_config_path)
    pipeline.setup()
    train_loader = pipeline.get_train_dataloader()
    val_loader = pipeline.get_val_dataloader() if 'validation' in pipeline.datasets else None
    
    # 2. åŠ è½½æ¨¡å‹
    logger.info("åŠ è½½æ¨¡å‹...")
    model_result = load_model(
        model_name=model_name,
        model_type=model_type,
        task=task,
        device=kwargs.get('device', 'cuda' if torch.cuda.is_available() else 'cpu'),
        load_processor=True
    )
    model = model_result['model']
    processor = model_result.get('processor')
    
    # 3. é…ç½®ä¼˜åŒ–å™¨
    optimizer_config = kwargs.get('optimizer', {})
    lr = optimizer_config.get('lr', 3e-5)
    weight_decay = optimizer_config.get('weight_decay', 0.01)
    optimizer_type = optimizer_config.get('type', 'adamw')
    
    if optimizer_type.lower() == 'adamw':
        optimizer = AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)
    elif optimizer_type.lower() == 'adam':
        optimizer = Adam(model.parameters(), lr=lr, weight_decay=weight_decay)
    elif optimizer_type.lower() == 'sgd':
        optimizer = SGD(model.parameters(), lr=lr, weight_decay=weight_decay)
    else:
        optimizer = AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)
    
    # 4. é…ç½®å­¦ä¹ ç‡è°ƒåº¦å™¨
    scheduler = None
    scheduler_config = kwargs.get('scheduler', {})
    if scheduler_config:
        scheduler_type = scheduler_config.get('type', 'cosine')
        if scheduler_type == 'cosine':
            scheduler = CosineAnnealingLR(
                optimizer,
                T_max=kwargs.get('num_epochs', 3)
            )
        elif scheduler_type == 'step':
            scheduler = StepLR(
                optimizer,
                step_size=scheduler_config.get('step_size', 1),
                gamma=scheduler_config.get('gamma', 0.1)
            )
        elif scheduler_type == 'reduce_on_plateau':
            scheduler = ReduceLROnPlateau(
                optimizer,
                mode='min',
                factor=scheduler_config.get('factor', 0.5),
                patience=scheduler_config.get('patience', 2)
            )
    
    # 5. åˆ›å»ºè¯„ä¼°å™¨
    evaluator = None
    if task == 'vqa' and processor:
        evaluator = VQAEvaluator(model, processor, device=kwargs.get('device'))
    else:
        evaluator = Evaluator(model, device=kwargs.get('device'))
    
    # 6. åˆ›å»ºå›è°ƒå‡½æ•°
    callbacks = []
    
    # è¿›åº¦æ¡
    callbacks.append(ProgressBarCallback(verbose=1))
    
    # æ—©åœ
    if kwargs.get('early_stopping', {}).get('enabled', False):
        callbacks.append(EarlyStoppingCallback(
            monitor=kwargs['early_stopping'].get('monitor', 'val_loss'),
            patience=kwargs['early_stopping'].get('patience', 5)
        ))
    
    # æ¨¡å‹æ£€æŸ¥ç‚¹
    save_dir = kwargs.get('save_dir', 'checkpoints')
    callbacks.append(ModelCheckpointCallback(
        save_dir=save_dir,
        monitor=kwargs.get('checkpoint_monitor', 'val_loss'),
        save_best_only=kwargs.get('save_best_only', True)
    ))
    
    # å­¦ä¹ ç‡è°ƒåº¦å™¨å›è°ƒ
    if scheduler:
        callbacks.append(LearningRateSchedulerCallback(scheduler))
    
    # TensorBoardï¼ˆå¦‚æœå¯ç”¨ï¼‰
    if kwargs.get('use_tensorboard', False):
        callbacks.append(TensorBoardCallback(log_dir=f'{save_dir}/tensorboard'))
    
    # CSVæ—¥å¿—
    callbacks.append(CSVLoggerCallback(filename=f'{save_dir}/training_log.csv'))
    
    # 7. å†»ç»“å±‚ï¼ˆå¦‚æœé…ç½®ï¼‰
    freeze_config = kwargs.get('freeze', {})
    if freeze_config.get('enabled', False):
        freeze_layers = freeze_config.get('layers', [])
        freeze_model(model, freeze_layers=freeze_layers if freeze_layers else None)
    
    # 8. åˆ›å»ºè®­ç»ƒå™¨
    trainer = Trainer(
        model=model,
        train_dataloader=train_loader,
        val_dataloader=val_loader,
        optimizer=optimizer,
        scheduler=scheduler,
        device=kwargs.get('device'),
        callbacks=callbacks,
        evaluator=evaluator,
        num_epochs=kwargs.get('num_epochs', 3),
        gradient_accumulation_steps=kwargs.get('gradient_accumulation_steps', 1),
        max_grad_norm=kwargs.get('max_grad_norm'),
        fp16=kwargs.get('fp16', False),
        save_dir=save_dir
    )
    
    return trainer


# ç¤ºä¾‹ç”¨æ³•
if __name__ == "__main__":
    import logging
    logging.basicConfig(level=logging.INFO)
    
    print("Traineræ¨¡å—åŠ è½½å®Œæˆ - æä¾›å®Œæ•´çš„è®­ç»ƒåŠŸèƒ½")
    print("\nä½¿ç”¨ç¤ºä¾‹:")
    print("""
    from training.trainer import create_trainer_from_config
    
    trainer = create_trainer_from_config(
        data_config_path='config/vqa_config.yaml',
        model_name='Salesforce/blip-vqa-base',
        model_type='blip',
        task='vqa',
        num_epochs=3,
        fp16=True
    )
    
    trainer.train()
    """)

